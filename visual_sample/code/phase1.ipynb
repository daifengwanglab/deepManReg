{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial.distance as sd\n",
    "from neighborhood import neighbor_graph, laplacian\n",
    "from correspondence import Correspondence\n",
    "from stiefel import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datareader import *\n",
    "import pandas as pd \n",
    "import os.path\n",
    "import pdb\n",
    "#cuda = torch.device('cuda') \n",
    "import scipy as sp\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from random import sample\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Defines the neural network\"\"\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H1)\n",
    "        self.linear2 = torch.nn.Linear(H1, H2)\n",
    "        self.linear3 = torch.nn.Linear(H2, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1_sigmoid = self.linear1(x).sigmoid()\n",
    "        h2_sigmoid = self.linear2(h1_sigmoid).sigmoid()\n",
    "        y_pred = self.linear3(h2_sigmoid)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_project(x1_np, x2_np):\n",
    "    \n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # N is batch size; D_in is input dimension;\n",
    "    # H is hidden dimension; D_out is output dimension.\n",
    "    N, D_in, H1, H2, D_out = x1_np.shape[0], x1_np.shape[1], 512, 64, 3\n",
    "\n",
    "    model = Net(D_in, H1, H2, D_out)\n",
    "\n",
    "    x1 = torch.from_numpy(x1_np.astype(np.float32))\n",
    "    x2 = torch.from_numpy(x2_np.astype(np.float32))\n",
    "    print(x1.dtype)\n",
    "    \n",
    "    adj1 = neighbor_graph(x1_np, k=5)\n",
    "    adj2 = neighbor_graph(x2_np, k=5)\n",
    "\n",
    "    #corr = Correspondence(matrix=np.eye(N))\n",
    "\n",
    "    w1 = np.corrcoef(x1, x2)[0:x1.shape[0],x1.shape[0]:(x1.shape[0]+x2.shape[0])]\n",
    "    w1[abs(w1) > 0.5] = 1\n",
    "    w1[w1 != 1] = 0\n",
    "    w = np.block([[w1,adj1],\n",
    "                  [adj2,w1.T]])\n",
    "\n",
    "    L_np = laplacian(w, normed=False)\n",
    "    L = torch.from_numpy(L_np.astype(np.float32))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.00001)\n",
    "    \n",
    "    for t in range(500):\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y1_pred = model(x1)\n",
    "        y2_pred = model(x2)\n",
    "\n",
    "        outputs = torch.cat((y1_pred, y2_pred), 0)\n",
    "        \n",
    "        # Project the output onto Stiefel Manifold\n",
    "        u, s, v = torch.svd(outputs, some=True)\n",
    "        proj_outputs = u@v.t()\n",
    "\n",
    "        # Compute and print loss\n",
    "        print(L.dtype)\n",
    "        loss = torch.trace(proj_outputs.t()@L@proj_outputs)\n",
    "        print(t, loss.item())\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        proj_outputs.retain_grad()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        # Project the (Euclidean) gradient onto the tangent space of Stiefel Manifold (to get Rimannian gradient)\n",
    "        rgrad = proj_stiefel(proj_outputs, proj_outputs.grad) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Backpropogate the Rimannian gradient w.r.t proj_outputs\n",
    "        proj_outputs.backward(rgrad)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    proj_outputs_np = proj_outputs.detach().numpy()\n",
    "    return proj_outputs_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of geneExp:  (5000, 3654)\n",
      "Shape of Efeature:  (3654, 41)\n",
      "(500, 3654)\n",
      "(41, 3654)\n"
     ]
    }
   ],
   "source": [
    "Efeature = pd.read_csv('../data/efeature_filtered.csv',index_col=0)\n",
    "geneExp = pd.read_csv('../data/expMat_filtered_5000.csv',index_col=0)\n",
    "label = pd.read_csv('../data/label_visual.csv')\n",
    "print('Shape of geneExp: ', geneExp.shape)\n",
    "print('Shape of Efeature: ', Efeature.shape)\n",
    "\n",
    "#x1_np = preprocessing.scale(np.log(geneExp+1).to_numpy())\n",
    "#x2_np = preprocessing.scale(Efeature.T.to_numpy())\n",
    "\n",
    "x1_np = np.log(geneExp+1).to_numpy()[0:500]\n",
    "x2_np = preprocessing.scale(Efeature.T.to_numpy())\n",
    "\n",
    "print(x1_np.shape)\n",
    "print(x2_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "0 15.873481750488281\n",
      "torch.float32\n",
      "1 15.023713111877441\n",
      "torch.float32\n",
      "2 14.522339820861816\n",
      "torch.float32\n",
      "3 13.960118293762207\n",
      "torch.float32\n",
      "4 13.435967445373535\n",
      "torch.float32\n",
      "5 13.023812294006348\n",
      "torch.float32\n",
      "6 12.69229507446289\n",
      "torch.float32\n",
      "7 12.383977890014648\n",
      "torch.float32\n",
      "8 12.074462890625\n",
      "torch.float32\n",
      "9 11.763294219970703\n",
      "torch.float32\n",
      "10 11.461114883422852\n",
      "torch.float32\n",
      "11 11.177868843078613\n",
      "torch.float32\n",
      "12 10.910758972167969\n",
      "torch.float32\n",
      "13 10.648717880249023\n",
      "torch.float32\n",
      "14 10.39211368560791\n",
      "torch.float32\n",
      "15 10.156060218811035\n",
      "torch.float32\n",
      "16 9.949861526489258\n",
      "torch.float32\n",
      "17 9.763043403625488\n",
      "torch.float32\n",
      "18 9.578285217285156\n",
      "torch.float32\n",
      "19 9.389330863952637\n",
      "torch.float32\n",
      "20 9.200474739074707\n",
      "torch.float32\n",
      "21 9.016444206237793\n",
      "torch.float32\n",
      "22 8.838644027709961\n",
      "torch.float32\n",
      "23 8.667415618896484\n",
      "torch.float32\n",
      "24 8.503211975097656\n",
      "torch.float32\n",
      "25 8.347084999084473\n",
      "torch.float32\n",
      "26 8.200505256652832\n",
      "torch.float32\n",
      "27 8.062524795532227\n",
      "torch.float32\n",
      "28 7.928869724273682\n",
      "torch.float32\n",
      "29 7.796959400177002\n",
      "torch.float32\n",
      "30 7.669070720672607\n",
      "torch.float32\n",
      "31 7.547507286071777\n",
      "torch.float32\n",
      "32 7.430211067199707\n",
      "torch.float32\n",
      "33 7.314782619476318\n",
      "torch.float32\n",
      "34 7.202837944030762\n",
      "torch.float32\n",
      "35 7.096381664276123\n",
      "torch.float32\n",
      "36 6.993518829345703\n",
      "torch.float32\n",
      "37 6.89155387878418\n",
      "torch.float32\n",
      "38 6.790771961212158\n",
      "torch.float32\n",
      "39 6.692784786224365\n",
      "torch.float32\n",
      "40 6.598022937774658\n",
      "torch.float32\n",
      "41 6.506189346313477\n",
      "torch.float32\n",
      "42 6.417582988739014\n",
      "torch.float32\n",
      "43 6.332498550415039\n",
      "torch.float32\n",
      "44 6.249796390533447\n",
      "torch.float32\n",
      "45 6.167903900146484\n",
      "torch.float32\n",
      "46 6.08725118637085\n",
      "torch.float32\n",
      "47 6.009293556213379\n",
      "torch.float32\n",
      "48 5.933919429779053\n",
      "torch.float32\n",
      "49 5.860495567321777\n",
      "torch.float32\n",
      "50 5.789433479309082\n",
      "torch.float32\n",
      "51 5.7204365730285645\n",
      "torch.float32\n",
      "52 5.652493000030518\n",
      "torch.float32\n",
      "53 5.585813999176025\n",
      "torch.float32\n",
      "54 5.5209174156188965\n",
      "torch.float32\n",
      "55 5.457430839538574\n",
      "torch.float32\n",
      "56 5.39530611038208\n",
      "torch.float32\n",
      "57 5.334947109222412\n",
      "torch.float32\n",
      "58 5.276149749755859\n",
      "torch.float32\n",
      "59 5.2185163497924805\n",
      "torch.float32\n",
      "60 5.162186145782471\n",
      "torch.float32\n",
      "61 5.107381820678711\n",
      "torch.float32\n",
      "62 5.054041385650635\n",
      "torch.float32\n",
      "63 5.002203464508057\n",
      "torch.float32\n",
      "64 4.951816082000732\n",
      "torch.float32\n",
      "65 4.902437210083008\n",
      "torch.float32\n",
      "66 4.854082107543945\n",
      "torch.float32\n",
      "67 4.80707311630249\n",
      "torch.float32\n",
      "68 4.761299133300781\n",
      "torch.float32\n",
      "69 4.716737747192383\n",
      "torch.float32\n",
      "70 4.673369884490967\n",
      "torch.float32\n",
      "71 4.630954742431641\n",
      "torch.float32\n",
      "72 4.589591979980469\n",
      "torch.float32\n",
      "73 4.549353122711182\n",
      "torch.float32\n",
      "74 4.5101423263549805\n",
      "torch.float32\n",
      "75 4.472017288208008\n",
      "torch.float32\n",
      "76 4.434902191162109\n",
      "torch.float32\n",
      "77 4.398675918579102\n",
      "torch.float32\n",
      "78 4.363365650177002\n",
      "torch.float32\n",
      "79 4.328956604003906\n",
      "torch.float32\n",
      "80 4.295443534851074\n",
      "torch.float32\n",
      "81 4.2628254890441895\n",
      "torch.float32\n",
      "82 4.230989456176758\n",
      "torch.float32\n",
      "83 4.199939250946045\n",
      "torch.float32\n",
      "84 4.169708251953125\n",
      "torch.float32\n",
      "85 4.140264511108398\n",
      "torch.float32\n",
      "86 4.111606597900391\n",
      "torch.float32\n",
      "87 4.083650588989258\n",
      "torch.float32\n",
      "88 4.05640172958374\n",
      "torch.float32\n",
      "89 4.029866695404053\n",
      "torch.float32\n",
      "90 4.004009246826172\n",
      "torch.float32\n",
      "91 3.9788413047790527\n",
      "torch.float32\n",
      "92 3.9542999267578125\n",
      "torch.float32\n",
      "93 3.9303719997406006\n",
      "torch.float32\n",
      "94 3.9070346355438232\n",
      "torch.float32\n",
      "95 3.8842856884002686\n",
      "torch.float32\n",
      "96 3.8621177673339844\n",
      "torch.float32\n",
      "97 3.8404881954193115\n",
      "torch.float32\n",
      "98 3.8193812370300293\n",
      "torch.float32\n",
      "99 3.7987794876098633\n",
      "torch.float32\n",
      "100 3.778676986694336\n",
      "torch.float32\n",
      "101 3.7590441703796387\n",
      "torch.float32\n",
      "102 3.739861488342285\n",
      "torch.float32\n",
      "103 3.7211170196533203\n",
      "torch.float32\n",
      "104 3.7027876377105713\n",
      "torch.float32\n",
      "105 3.684863567352295\n",
      "torch.float32\n",
      "106 3.6673240661621094\n",
      "torch.float32\n",
      "107 3.6501564979553223\n",
      "torch.float32\n",
      "108 3.6333398818969727\n",
      "torch.float32\n",
      "109 3.6168694496154785\n",
      "torch.float32\n",
      "110 3.600724220275879\n",
      "torch.float32\n",
      "111 3.5848915576934814\n",
      "torch.float32\n",
      "112 3.5693554878234863\n",
      "torch.float32\n",
      "113 3.5541086196899414\n",
      "torch.float32\n",
      "114 3.5391387939453125\n",
      "torch.float32\n",
      "115 3.5244314670562744\n",
      "torch.float32\n",
      "116 3.5099751949310303\n",
      "torch.float32\n",
      "117 3.495762348175049\n",
      "torch.float32\n",
      "118 3.481781482696533\n",
      "torch.float32\n",
      "119 3.468018054962158\n",
      "torch.float32\n",
      "120 3.4544677734375\n",
      "torch.float32\n",
      "121 3.4411203861236572\n",
      "torch.float32\n",
      "122 3.427966356277466\n",
      "torch.float32\n",
      "123 3.414997100830078\n",
      "torch.float32\n",
      "124 3.4022037982940674\n",
      "torch.float32\n",
      "125 3.3895792961120605\n",
      "torch.float32\n",
      "126 3.377115249633789\n",
      "torch.float32\n",
      "127 3.3648059368133545\n",
      "torch.float32\n",
      "128 3.352642059326172\n",
      "torch.float32\n",
      "129 3.3406167030334473\n",
      "torch.float32\n",
      "130 3.3287277221679688\n",
      "torch.float32\n",
      "131 3.3169608116149902\n",
      "torch.float32\n",
      "132 3.3053174018859863\n",
      "torch.float32\n",
      "133 3.29378604888916\n",
      "torch.float32\n",
      "134 3.2823634147644043\n",
      "torch.float32\n",
      "135 3.2710437774658203\n",
      "torch.float32\n",
      "136 3.2598178386688232\n",
      "torch.float32\n",
      "137 3.2486860752105713\n",
      "torch.float32\n",
      "138 3.237639904022217\n",
      "torch.float32\n",
      "139 3.2266738414764404\n",
      "torch.float32\n",
      "140 3.21578311920166\n",
      "torch.float32\n",
      "141 3.204962730407715\n",
      "torch.float32\n",
      "142 3.1942081451416016\n",
      "torch.float32\n",
      "143 3.1835155487060547\n",
      "torch.float32\n",
      "144 3.1728780269622803\n",
      "torch.float32\n",
      "145 3.1622936725616455\n",
      "torch.float32\n",
      "146 3.1517579555511475\n",
      "torch.float32\n",
      "147 3.141263484954834\n",
      "torch.float32\n",
      "148 3.1308109760284424\n",
      "torch.float32\n",
      "149 3.120394468307495\n",
      "torch.float32\n",
      "150 3.1100070476531982\n",
      "torch.float32\n",
      "151 3.0996482372283936\n",
      "torch.float32\n",
      "152 3.089317560195923\n",
      "torch.float32\n",
      "153 3.079005241394043\n",
      "torch.float32\n",
      "154 3.0687124729156494\n",
      "torch.float32\n",
      "155 3.058434247970581\n",
      "torch.float32\n",
      "156 3.048170804977417\n",
      "torch.float32\n",
      "157 3.0379154682159424\n",
      "torch.float32\n",
      "158 3.0276684761047363\n",
      "torch.float32\n",
      "159 3.0174241065979004\n",
      "torch.float32\n",
      "160 3.0071847438812256\n",
      "torch.float32\n",
      "161 2.996943235397339\n",
      "torch.float32\n",
      "162 2.986699342727661\n",
      "torch.float32\n",
      "163 2.9764561653137207\n",
      "torch.float32\n",
      "164 2.9662058353424072\n",
      "torch.float32\n",
      "165 2.9559483528137207\n",
      "torch.float32\n",
      "166 2.9456863403320312\n",
      "torch.float32\n",
      "167 2.9354143142700195\n",
      "torch.float32\n",
      "168 2.9251370429992676\n",
      "torch.float32\n",
      "169 2.9148480892181396\n",
      "torch.float32\n",
      "170 2.9045557975769043\n",
      "torch.float32\n",
      "171 2.8942534923553467\n",
      "torch.float32\n",
      "172 2.8839471340179443\n",
      "torch.float32\n",
      "173 2.8736367225646973\n",
      "torch.float32\n",
      "174 2.8633220195770264\n",
      "torch.float32\n",
      "175 2.8530116081237793\n",
      "torch.float32\n",
      "176 2.842700719833374\n",
      "torch.float32\n",
      "177 2.8323962688446045\n",
      "torch.float32\n",
      "178 2.822105884552002\n",
      "torch.float32\n",
      "179 2.811846971511841\n",
      "torch.float32\n",
      "180 2.8016750812530518\n",
      "torch.float32\n",
      "181 2.7918004989624023\n",
      "torch.float32\n",
      "182 2.783090829849243\n",
      "torch.float32\n",
      "183 2.7789320945739746\n",
      "torch.float32\n",
      "184 2.7906219959259033\n",
      "torch.float32\n",
      "185 2.8241496086120605\n",
      "torch.float32\n",
      "186 2.817678689956665\n",
      "torch.float32\n",
      "187 2.7429561614990234\n",
      "torch.float32\n",
      "188 2.762373447418213\n",
      "torch.float32\n",
      "189 2.767672300338745\n",
      "torch.float32\n",
      "190 2.711047410964966\n",
      "torch.float32\n",
      "191 2.7361857891082764\n",
      "torch.float32\n",
      "192 2.732895612716675\n",
      "torch.float32\n",
      "193 2.6870715618133545\n",
      "torch.float32\n",
      "194 2.7055091857910156\n",
      "torch.float32\n",
      "195 2.692368507385254\n",
      "torch.float32\n",
      "196 2.6669468879699707\n",
      "torch.float32\n",
      "197 2.681887149810791\n",
      "torch.float32\n",
      "198 2.653795003890991\n",
      "torch.float32\n",
      "199 2.652193069458008\n",
      "torch.float32\n",
      "200 2.6533055305480957\n",
      "torch.float32\n",
      "201 2.628204107284546\n",
      "torch.float32\n",
      "202 2.632829189300537\n",
      "torch.float32\n",
      "203 2.6239781379699707\n",
      "torch.float32\n",
      "204 2.6081135272979736\n",
      "torch.float32\n",
      "205 2.612217664718628\n",
      "torch.float32\n",
      "206 2.596735715866089\n",
      "torch.float32\n",
      "207 2.5908548831939697\n",
      "torch.float32\n",
      "208 2.589493751525879\n",
      "torch.float32\n",
      "209 2.574847936630249\n",
      "torch.float32\n",
      "210 2.5724897384643555\n",
      "torch.float32\n",
      "211 2.566957950592041\n",
      "torch.float32\n",
      "212 2.5554914474487305\n",
      "torch.float32\n",
      "213 2.5539040565490723\n",
      "torch.float32\n",
      "214 2.5457377433776855\n",
      "torch.float32\n",
      "215 2.537572145462036\n",
      "torch.float32\n",
      "216 2.5352985858917236\n",
      "torch.float32\n",
      "217 2.5268380641937256\n",
      "torch.float32\n",
      "218 2.5202114582061768\n",
      "torch.float32\n",
      "219 2.516899347305298\n",
      "torch.float32\n",
      "220 2.5090205669403076\n",
      "torch.float32\n",
      "221 2.5035691261291504\n",
      "torch.float32\n",
      "222 2.4995906352996826\n",
      "torch.float32\n",
      "223 2.492351770401001\n",
      "torch.float32\n",
      "224 2.487244129180908\n",
      "torch.float32\n",
      "225 2.4831032752990723\n",
      "torch.float32\n",
      "226 2.4765992164611816\n",
      "torch.float32\n",
      "227 2.4716243743896484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "228 2.467444658279419\n",
      "torch.float32\n",
      "229 2.461538314819336\n",
      "torch.float32\n",
      "230 2.456616163253784\n",
      "torch.float32\n",
      "231 2.4525694847106934\n",
      "torch.float32\n",
      "232 2.4472692012786865\n",
      "torch.float32\n",
      "233 2.4423043727874756\n",
      "torch.float32\n",
      "234 2.438297748565674\n",
      "torch.float32\n",
      "235 2.4335763454437256\n",
      "torch.float32\n",
      "236 2.428725242614746\n",
      "torch.float32\n",
      "237 2.4246859550476074\n",
      "torch.float32\n",
      "238 2.420468330383301\n",
      "torch.float32\n",
      "239 2.415837049484253\n",
      "torch.float32\n",
      "240 2.411689281463623\n",
      "torch.float32\n",
      "241 2.4078099727630615\n",
      "torch.float32\n",
      "242 2.403571367263794\n",
      "torch.float32\n",
      "243 2.3993799686431885\n",
      "torch.float32\n",
      "244 2.3955891132354736\n",
      "torch.float32\n",
      "245 2.3917620182037354\n",
      "torch.float32\n",
      "246 2.3877315521240234\n",
      "torch.float32\n",
      "247 2.383899211883545\n",
      "torch.float32\n",
      "248 2.3802998065948486\n",
      "torch.float32\n",
      "249 2.3765978813171387\n",
      "torch.float32\n",
      "250 2.37282133102417\n",
      "torch.float32\n",
      "251 2.3692235946655273\n",
      "torch.float32\n",
      "252 2.365762948989868\n",
      "torch.float32\n",
      "253 2.362238645553589\n",
      "torch.float32\n",
      "254 2.3586912155151367\n",
      "torch.float32\n",
      "255 2.355264663696289\n",
      "torch.float32\n",
      "256 2.3519439697265625\n",
      "torch.float32\n",
      "257 2.3486108779907227\n",
      "torch.float32\n",
      "258 2.3452529907226562\n",
      "torch.float32\n",
      "259 2.341965913772583\n",
      "torch.float32\n",
      "260 2.338775157928467\n",
      "torch.float32\n",
      "261 2.3356077671051025\n",
      "torch.float32\n",
      "262 2.332427740097046\n",
      "torch.float32\n",
      "263 2.329272747039795\n",
      "torch.float32\n",
      "264 2.3261828422546387\n",
      "torch.float32\n",
      "265 2.3231515884399414\n",
      "torch.float32\n",
      "266 2.320136308670044\n",
      "torch.float32\n",
      "267 2.317126989364624\n",
      "torch.float32\n",
      "268 2.3141424655914307\n",
      "torch.float32\n",
      "269 2.3112075328826904\n",
      "torch.float32\n",
      "270 2.3083157539367676\n",
      "torch.float32\n",
      "271 2.305450439453125\n",
      "torch.float32\n",
      "272 2.302600145339966\n",
      "torch.float32\n",
      "273 2.299769878387451\n",
      "torch.float32\n",
      "274 2.2969725131988525\n",
      "torch.float32\n",
      "275 2.2942209243774414\n",
      "torch.float32\n",
      "276 2.291517734527588\n",
      "torch.float32\n",
      "277 2.288874864578247\n",
      "torch.float32\n",
      "278 2.2863268852233887\n",
      "torch.float32\n",
      "279 2.2839643955230713\n",
      "torch.float32\n",
      "280 2.2819786071777344\n",
      "torch.float32\n",
      "281 2.280818223953247\n",
      "torch.float32\n",
      "282 2.281280279159546\n",
      "torch.float32\n",
      "283 2.2849507331848145\n",
      "torch.float32\n",
      "284 2.291717052459717\n",
      "torch.float32\n",
      "285 2.2989728450775146\n",
      "torch.float32\n",
      "286 2.291944742202759\n",
      "torch.float32\n",
      "287 2.2743940353393555\n",
      "torch.float32\n",
      "288 2.2619757652282715\n",
      "torch.float32\n",
      "289 2.2655251026153564\n",
      "torch.float32\n",
      "290 2.2748055458068848\n",
      "torch.float32\n",
      "291 2.275362253189087\n",
      "torch.float32\n",
      "292 2.2629830837249756\n",
      "torch.float32\n",
      "293 2.2533581256866455\n",
      "torch.float32\n",
      "294 2.259481430053711\n",
      "torch.float32\n",
      "295 2.2634212970733643\n",
      "torch.float32\n",
      "296 2.2552647590637207\n",
      "torch.float32\n",
      "297 2.2476587295532227\n",
      "torch.float32\n",
      "298 2.2477259635925293\n",
      "torch.float32\n",
      "299 2.2473907470703125\n",
      "torch.float32\n",
      "300 2.2400498390197754\n",
      "torch.float32\n",
      "301 2.2362873554229736\n",
      "torch.float32\n",
      "302 2.240387439727783\n",
      "torch.float32\n",
      "303 2.2376654148101807\n",
      "torch.float32\n",
      "304 2.228651523590088\n",
      "torch.float32\n",
      "305 2.2261099815368652\n",
      "torch.float32\n",
      "306 2.22922945022583\n",
      "torch.float32\n",
      "307 2.2284719944000244\n",
      "torch.float32\n",
      "308 2.223947286605835\n",
      "torch.float32\n",
      "309 2.221982479095459\n",
      "torch.float32\n",
      "310 2.21958589553833\n",
      "torch.float32\n",
      "311 2.2154905796051025\n",
      "torch.float32\n",
      "312 2.213165283203125\n",
      "torch.float32\n",
      "313 2.214116096496582\n",
      "torch.float32\n",
      "314 2.2140629291534424\n",
      "torch.float32\n",
      "315 2.2095558643341064\n",
      "torch.float32\n",
      "316 2.2059507369995117\n",
      "torch.float32\n",
      "317 2.2049758434295654\n",
      "torch.float32\n",
      "318 2.2032275199890137\n",
      "torch.float32\n",
      "319 2.201179027557373\n",
      "torch.float32\n",
      "320 2.2005672454833984\n",
      "torch.float32\n",
      "321 2.1995415687561035\n",
      "torch.float32\n",
      "322 2.196765899658203\n",
      "torch.float32\n",
      "323 2.1939995288848877\n",
      "torch.float32\n",
      "324 2.192243814468384\n",
      "torch.float32\n",
      "325 2.190991163253784\n",
      "torch.float32\n",
      "326 2.1891469955444336\n",
      "torch.float32\n",
      "327 2.1875159740448\n",
      "torch.float32\n",
      "328 2.1866843700408936\n",
      "torch.float32\n",
      "329 2.1855416297912598\n",
      "torch.float32\n",
      "330 2.1838595867156982\n",
      "torch.float32\n",
      "331 2.1822292804718018\n",
      "torch.float32\n",
      "332 2.1808485984802246\n",
      "torch.float32\n",
      "333 2.17928147315979\n",
      "torch.float32\n",
      "334 2.177497386932373\n",
      "torch.float32\n",
      "335 2.1758320331573486\n",
      "torch.float32\n",
      "336 2.174546718597412\n",
      "torch.float32\n",
      "337 2.173180103302002\n",
      "torch.float32\n",
      "338 2.171644449234009\n",
      "torch.float32\n",
      "339 2.1702606678009033\n",
      "torch.float32\n",
      "340 2.1690430641174316\n",
      "torch.float32\n",
      "341 2.167827844619751\n",
      "torch.float32\n",
      "342 2.1665027141571045\n",
      "torch.float32\n",
      "343 2.16520357131958\n",
      "torch.float32\n",
      "344 2.164071798324585\n",
      "torch.float32\n",
      "345 2.1629886627197266\n",
      "torch.float32\n",
      "346 2.161860227584839\n",
      "torch.float32\n",
      "347 2.1608388423919678\n",
      "torch.float32\n",
      "348 2.1600234508514404\n",
      "torch.float32\n",
      "349 2.1595537662506104\n",
      "torch.float32\n",
      "350 2.1595077514648438\n",
      "torch.float32\n",
      "351 2.1606369018554688\n",
      "torch.float32\n",
      "352 2.16304349899292\n",
      "torch.float32\n",
      "353 2.168680429458618\n",
      "torch.float32\n",
      "354 2.173114538192749\n",
      "torch.float32\n",
      "355 2.179497003555298\n",
      "torch.float32\n",
      "356 2.1730504035949707\n",
      "torch.float32\n",
      "357 2.1634280681610107\n",
      "torch.float32\n",
      "358 2.1516940593719482\n",
      "torch.float32\n",
      "359 2.1480231285095215\n",
      "torch.float32\n",
      "360 2.151625394821167\n",
      "torch.float32\n",
      "361 2.1581904888153076\n",
      "torch.float32\n",
      "362 2.1639206409454346\n",
      "torch.float32\n",
      "363 2.1567559242248535\n",
      "torch.float32\n",
      "364 2.1466000080108643\n",
      "torch.float32\n",
      "365 2.1428699493408203\n",
      "torch.float32\n",
      "366 2.147002935409546\n",
      "torch.float32\n",
      "367 2.1541261672973633\n",
      "torch.float32\n",
      "368 2.1552653312683105\n",
      "torch.float32\n",
      "369 2.148442506790161\n",
      "torch.float32\n",
      "370 2.1392405033111572\n",
      "torch.float32\n",
      "371 2.1408257484436035\n",
      "torch.float32\n",
      "372 2.1490492820739746\n",
      "torch.float32\n",
      "373 2.153202772140503\n",
      "torch.float32\n",
      "374 2.150125503540039\n",
      "torch.float32\n",
      "375 2.137903928756714\n",
      "torch.float32\n",
      "376 2.1368014812469482\n",
      "torch.float32\n",
      "377 2.1480681896209717\n",
      "torch.float32\n",
      "378 2.1533243656158447\n",
      "torch.float32\n",
      "379 2.149625778198242\n",
      "torch.float32\n",
      "380 2.1360700130462646\n",
      "torch.float32\n",
      "381 2.135436773300171\n",
      "torch.float32\n",
      "382 2.147480010986328\n",
      "torch.float32\n",
      "383 2.149519443511963\n",
      "torch.float32\n",
      "384 2.140498638153076\n",
      "torch.float32\n",
      "385 2.1308388710021973\n",
      "torch.float32\n",
      "386 2.134226083755493\n",
      "torch.float32\n",
      "387 2.1405675411224365\n",
      "torch.float32\n",
      "388 2.136535406112671\n",
      "torch.float32\n",
      "389 2.128469944000244\n",
      "torch.float32\n",
      "390 2.12693190574646\n",
      "torch.float32\n",
      "391 2.1310346126556396\n",
      "torch.float32\n",
      "392 2.130446434020996\n",
      "torch.float32\n",
      "393 2.125852346420288\n",
      "torch.float32\n",
      "394 2.124638080596924\n",
      "torch.float32\n",
      "395 2.1267096996307373\n",
      "torch.float32\n",
      "396 2.1271843910217285\n",
      "torch.float32\n",
      "397 2.124351978302002\n",
      "torch.float32\n",
      "398 2.1222336292266846\n",
      "torch.float32\n",
      "399 2.1235787868499756\n",
      "torch.float32\n",
      "400 2.124842882156372\n",
      "torch.float32\n",
      "401 2.122887372970581\n",
      "torch.float32\n",
      "402 2.1206748485565186\n",
      "torch.float32\n",
      "403 2.120447874069214\n",
      "torch.float32\n",
      "404 2.121230363845825\n",
      "torch.float32\n",
      "405 2.1210145950317383\n",
      "torch.float32\n",
      "406 2.119230031967163\n",
      "torch.float32\n",
      "407 2.1181631088256836\n",
      "torch.float32\n",
      "408 2.1184349060058594\n",
      "torch.float32\n",
      "409 2.118455648422241\n",
      "torch.float32\n",
      "410 2.1176366806030273\n",
      "torch.float32\n",
      "411 2.1166465282440186\n",
      "torch.float32\n",
      "412 2.1162610054016113\n",
      "torch.float32\n",
      "413 2.1163229942321777\n",
      "torch.float32\n",
      "414 2.1160173416137695\n",
      "torch.float32\n",
      "415 2.115229845046997\n",
      "torch.float32\n",
      "416 2.1146399974823\n",
      "torch.float32\n",
      "417 2.114470958709717\n",
      "torch.float32\n",
      "418 2.1143205165863037\n",
      "torch.float32\n",
      "419 2.1139180660247803\n",
      "torch.float32\n",
      "420 2.1133151054382324\n",
      "torch.float32\n",
      "421 2.1128571033477783\n",
      "torch.float32\n",
      "422 2.112672805786133\n",
      "torch.float32\n",
      "423 2.1124603748321533\n",
      "torch.float32\n",
      "424 2.1120662689208984\n",
      "torch.float32\n",
      "425 2.1115972995758057\n",
      "torch.float32\n",
      "426 2.1111984252929688\n",
      "torch.float32\n",
      "427 2.1109461784362793\n",
      "torch.float32\n",
      "428 2.1107239723205566\n",
      "torch.float32\n",
      "429 2.11039137840271\n",
      "torch.float32\n",
      "430 2.1100056171417236\n",
      "torch.float32\n",
      "431 2.109647274017334\n",
      "torch.float32\n",
      "432 2.109351634979248\n",
      "torch.float32\n",
      "433 2.1091089248657227\n",
      "torch.float32\n",
      "434 2.108835220336914\n",
      "torch.float32\n",
      "435 2.1085164546966553\n",
      "torch.float32\n",
      "436 2.108196496963501\n",
      "torch.float32\n",
      "437 2.1078927516937256\n",
      "torch.float32\n",
      "438 2.1076254844665527\n",
      "torch.float32\n",
      "439 2.1073718070983887\n",
      "torch.float32\n",
      "440 2.1071043014526367\n",
      "torch.float32\n",
      "441 2.106826066970825\n",
      "torch.float32\n",
      "442 2.106546640396118\n",
      "torch.float32\n",
      "443 2.106271743774414\n",
      "torch.float32\n",
      "444 2.106013774871826\n",
      "torch.float32\n",
      "445 2.105764627456665\n",
      "torch.float32\n",
      "446 2.105515480041504\n",
      "torch.float32\n",
      "447 2.1052708625793457\n",
      "torch.float32\n",
      "448 2.105020523071289\n",
      "torch.float32\n",
      "449 2.1047682762145996\n",
      "torch.float32\n",
      "450 2.1045238971710205\n",
      "torch.float32\n",
      "451 2.104280471801758\n",
      "torch.float32\n",
      "452 2.10404896736145\n",
      "torch.float32\n",
      "453 2.1038224697113037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "454 2.1035964488983154\n",
      "torch.float32\n",
      "455 2.1033718585968018\n",
      "torch.float32\n",
      "456 2.1031441688537598\n",
      "torch.float32\n",
      "457 2.1029176712036133\n",
      "torch.float32\n",
      "458 2.1026947498321533\n",
      "torch.float32\n",
      "459 2.1024768352508545\n",
      "torch.float32\n",
      "460 2.1022655963897705\n",
      "torch.float32\n",
      "461 2.1020588874816895\n",
      "torch.float32\n",
      "462 2.1018526554107666\n",
      "torch.float32\n",
      "463 2.101646900177002\n",
      "torch.float32\n",
      "464 2.1014416217803955\n",
      "torch.float32\n",
      "465 2.1012377738952637\n",
      "torch.float32\n",
      "466 2.1010348796844482\n",
      "torch.float32\n",
      "467 2.1008377075195312\n",
      "torch.float32\n",
      "468 2.1006405353546143\n",
      "torch.float32\n",
      "469 2.100449562072754\n",
      "torch.float32\n",
      "470 2.1002585887908936\n",
      "torch.float32\n",
      "471 2.1000709533691406\n",
      "torch.float32\n",
      "472 2.099884271621704\n",
      "torch.float32\n",
      "473 2.099701166152954\n",
      "torch.float32\n",
      "474 2.0995194911956787\n",
      "torch.float32\n",
      "475 2.099339723587036\n",
      "torch.float32\n",
      "476 2.0991599559783936\n",
      "torch.float32\n",
      "477 2.0989842414855957\n",
      "torch.float32\n",
      "478 2.098809003829956\n",
      "torch.float32\n",
      "479 2.0986363887786865\n",
      "torch.float32\n",
      "480 2.098466157913208\n",
      "torch.float32\n",
      "481 2.098296642303467\n",
      "torch.float32\n",
      "482 2.0981290340423584\n",
      "torch.float32\n",
      "483 2.097965955734253\n",
      "torch.float32\n",
      "484 2.097801446914673\n",
      "torch.float32\n",
      "485 2.0976412296295166\n",
      "torch.float32\n",
      "486 2.097482442855835\n",
      "torch.float32\n",
      "487 2.0973258018493652\n",
      "torch.float32\n",
      "488 2.0971736907958984\n",
      "torch.float32\n",
      "489 2.0970277786254883\n",
      "torch.float32\n",
      "490 2.0968880653381348\n",
      "torch.float32\n",
      "491 2.0967581272125244\n",
      "torch.float32\n",
      "492 2.0966501235961914\n",
      "torch.float32\n",
      "493 2.0965707302093506\n",
      "torch.float32\n",
      "494 2.0965428352355957\n",
      "torch.float32\n",
      "495 2.096606492996216\n",
      "torch.float32\n",
      "496 2.0968446731567383\n",
      "torch.float32\n",
      "497 2.0973551273345947\n",
      "torch.float32\n",
      "498 2.0984489917755127\n",
      "torch.float32\n",
      "499 2.1003153324127197\n"
     ]
    }
   ],
   "source": [
    "projections = train_and_project(x1_np, x2_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adarb2</th>\n",
       "      <td>-0.026649</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>-0.010327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sst</th>\n",
       "      <td>-0.009147</td>\n",
       "      <td>0.016273</td>\n",
       "      <td>-0.017417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vip</th>\n",
       "      <td>-0.026710</td>\n",
       "      <td>0.016914</td>\n",
       "      <td>0.000659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Npy</th>\n",
       "      <td>-0.023905</td>\n",
       "      <td>0.020164</td>\n",
       "      <td>-0.008712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synpr</th>\n",
       "      <td>-0.011319</td>\n",
       "      <td>0.032751</td>\n",
       "      <td>-0.017051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast_trough_v_short_square</th>\n",
       "      <td>-0.011954</td>\n",
       "      <td>0.022355</td>\n",
       "      <td>-0.010206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast_trough_t_short_square</th>\n",
       "      <td>-0.014934</td>\n",
       "      <td>0.015737</td>\n",
       "      <td>-0.020701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_v_short_square</th>\n",
       "      <td>-0.011773</td>\n",
       "      <td>0.018150</td>\n",
       "      <td>-0.017844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_i_short_square</th>\n",
       "      <td>-0.009439</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>-0.028545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_t_short_square</th>\n",
       "      <td>-0.014933</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>-0.020706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>541 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0         1         2\n",
       "Adarb2                     -0.026649  0.005948 -0.010327\n",
       "Sst                        -0.009147  0.016273 -0.017417\n",
       "Vip                        -0.026710  0.016914  0.000659\n",
       "Npy                        -0.023905  0.020164 -0.008712\n",
       "Synpr                      -0.011319  0.032751 -0.017051\n",
       "...                              ...       ...       ...\n",
       "fast_trough_v_short_square -0.011954  0.022355 -0.010206\n",
       "fast_trough_t_short_square -0.014934  0.015737 -0.020701\n",
       "threshold_v_short_square   -0.011773  0.018150 -0.017844\n",
       "threshold_i_short_square   -0.009439  0.010755 -0.028545\n",
       "threshold_t_short_square   -0.014933  0.015735 -0.020706\n",
       "\n",
       "[541 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projections = pd.DataFrame(projections)\n",
    "features = geneExp.index.tolist()[0:500]+Efeature.columns.tolist()\n",
    "projections.index = features\n",
    "projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections.to_csv(\"../data/deepmanreg_latent_500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
